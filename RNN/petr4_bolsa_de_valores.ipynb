{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uso de uma Rede Neural Recorrente, para prever investimentos na bolsa de valores**\n",
    "\n",
    "A base de dados representa investimentos nas ações da Petrobas na bolsa de valores, com o histórico do ano de 2013 ao ano de 2018.\n",
    "\n",
    "Você pode encontrar a base de dados, em:\n",
    "\n",
    "https://br.investing.com/equities/petrobras-pn-historical-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importações iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando da base de dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.read_csv('petr4_treinamento.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de treino é composta pelas seguintes features:\n",
    "\n",
    "* Date - Referente à data de abertura da ação;\n",
    "\n",
    "* Open - Referente ao valor na abertura da ação;\n",
    "\n",
    "* High - Referente ao valor máximo da ação;\n",
    "\n",
    "* Low - Referente ao valor mínimo da ação;\n",
    "\n",
    "* Close - Referente ao valor que a ação foi fechada;\n",
    "\n",
    "* Adj Close - Referente ao valor real previsto pela ação;\n",
    "\n",
    "* Volume - Total de investimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>20.209999</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>18.086271</td>\n",
       "      <td>30182600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>19.809999</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>18.738441</td>\n",
       "      <td>30552600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>20.170000</td>\n",
       "      <td>20.430000</td>\n",
       "      <td>18.766001</td>\n",
       "      <td>36141000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>20.480000</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>19.950001</td>\n",
       "      <td>20.080000</td>\n",
       "      <td>18.444506</td>\n",
       "      <td>28069600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.230000</td>\n",
       "      <td>19.459999</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>17.911745</td>\n",
       "      <td>29091300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>19.639999</td>\n",
       "      <td>19.870001</td>\n",
       "      <td>19.459999</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>18.077084</td>\n",
       "      <td>24361100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>20.049999</td>\n",
       "      <td>19.540001</td>\n",
       "      <td>19.830000</td>\n",
       "      <td>18.214869</td>\n",
       "      <td>17526200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>19.879999</td>\n",
       "      <td>18.260794</td>\n",
       "      <td>18223600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>20.240000</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.719999</td>\n",
       "      <td>18.113827</td>\n",
       "      <td>28302400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>20.240000</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.820000</td>\n",
       "      <td>18.205681</td>\n",
       "      <td>29633900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-01-16</td>\n",
       "      <td>19.889999</td>\n",
       "      <td>19.889999</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>19.840000</td>\n",
       "      <td>18.224054</td>\n",
       "      <td>16787800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-01-17</td>\n",
       "      <td>19.860001</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>19.709999</td>\n",
       "      <td>18.104639</td>\n",
       "      <td>19719600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>19.799999</td>\n",
       "      <td>19.889999</td>\n",
       "      <td>19.540001</td>\n",
       "      <td>19.580000</td>\n",
       "      <td>17.985229</td>\n",
       "      <td>18913900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-01-21</td>\n",
       "      <td>19.570000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>19.270000</td>\n",
       "      <td>19.389999</td>\n",
       "      <td>17.810705</td>\n",
       "      <td>18086200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-01-22</td>\n",
       "      <td>19.420000</td>\n",
       "      <td>19.610001</td>\n",
       "      <td>19.230000</td>\n",
       "      <td>19.580000</td>\n",
       "      <td>17.985229</td>\n",
       "      <td>23535100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>19.420000</td>\n",
       "      <td>19.629999</td>\n",
       "      <td>19.230000</td>\n",
       "      <td>19.549999</td>\n",
       "      <td>17.957674</td>\n",
       "      <td>17200800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013-01-24</td>\n",
       "      <td>19.370001</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>19.370001</td>\n",
       "      <td>19.610001</td>\n",
       "      <td>18.012787</td>\n",
       "      <td>19612600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>19.730000</td>\n",
       "      <td>19.809999</td>\n",
       "      <td>19.270000</td>\n",
       "      <td>19.370001</td>\n",
       "      <td>17.792336</td>\n",
       "      <td>20122600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>19.350000</td>\n",
       "      <td>19.370001</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>19.110001</td>\n",
       "      <td>17.553513</td>\n",
       "      <td>27097900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>18.170000</td>\n",
       "      <td>18.200001</td>\n",
       "      <td>16.717628</td>\n",
       "      <td>66985800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>18.330000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>18.080000</td>\n",
       "      <td>16.607405</td>\n",
       "      <td>33246400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>18.139999</td>\n",
       "      <td>18.650000</td>\n",
       "      <td>18.120001</td>\n",
       "      <td>18.459999</td>\n",
       "      <td>16.956451</td>\n",
       "      <td>28860400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>18.160000</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>17.889999</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>16.533920</td>\n",
       "      <td>32294300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>17.280001</td>\n",
       "      <td>18.290001</td>\n",
       "      <td>17.260000</td>\n",
       "      <td>18.080000</td>\n",
       "      <td>16.607405</td>\n",
       "      <td>77332900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013-02-06</td>\n",
       "      <td>17.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>17.530001</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>16.166500</td>\n",
       "      <td>30886100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2013-02-07</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>17.980000</td>\n",
       "      <td>17.320000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>16.074644</td>\n",
       "      <td>37066400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.780001</td>\n",
       "      <td>17.379999</td>\n",
       "      <td>17.740000</td>\n",
       "      <td>16.295095</td>\n",
       "      <td>31068100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>17.950001</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>17.730000</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>16.350208</td>\n",
       "      <td>22328200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>17.580000</td>\n",
       "      <td>17.670000</td>\n",
       "      <td>16.230797</td>\n",
       "      <td>25902900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>17.610001</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>17.530001</td>\n",
       "      <td>17.629999</td>\n",
       "      <td>16.194056</td>\n",
       "      <td>25001600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>2017-11-20</td>\n",
       "      <td>16.020000</td>\n",
       "      <td>16.020000</td>\n",
       "      <td>16.020000</td>\n",
       "      <td>16.020000</td>\n",
       "      <td>15.988025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>16.150000</td>\n",
       "      <td>16.309999</td>\n",
       "      <td>15.850000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>15.868263</td>\n",
       "      <td>45817800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>16.090000</td>\n",
       "      <td>16.240000</td>\n",
       "      <td>15.930000</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>16.077845</td>\n",
       "      <td>37444900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>15.980000</td>\n",
       "      <td>16.260000</td>\n",
       "      <td>15.940000</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.157686</td>\n",
       "      <td>15403600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.040001</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.067865</td>\n",
       "      <td>18790700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>16.010000</td>\n",
       "      <td>16.020000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>15.870000</td>\n",
       "      <td>15.838324</td>\n",
       "      <td>28445800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>15.930000</td>\n",
       "      <td>16.040001</td>\n",
       "      <td>15.810000</td>\n",
       "      <td>15.840000</td>\n",
       "      <td>15.808384</td>\n",
       "      <td>30429600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>15.870000</td>\n",
       "      <td>15.920000</td>\n",
       "      <td>15.320000</td>\n",
       "      <td>15.330000</td>\n",
       "      <td>15.299401</td>\n",
       "      <td>45973000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>15.470000</td>\n",
       "      <td>14.990000</td>\n",
       "      <td>15.380000</td>\n",
       "      <td>15.349302</td>\n",
       "      <td>52811400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>15.340000</td>\n",
       "      <td>15.770000</td>\n",
       "      <td>15.260000</td>\n",
       "      <td>15.610000</td>\n",
       "      <td>15.578842</td>\n",
       "      <td>42703800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>2017-12-04</td>\n",
       "      <td>15.650000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>15.460000</td>\n",
       "      <td>15.480000</td>\n",
       "      <td>15.449101</td>\n",
       "      <td>43821500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>15.830000</td>\n",
       "      <td>15.210000</td>\n",
       "      <td>15.310000</td>\n",
       "      <td>15.279442</td>\n",
       "      <td>30228000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>15.220000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>15.140000</td>\n",
       "      <td>15.520000</td>\n",
       "      <td>15.489023</td>\n",
       "      <td>39238500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>15.490000</td>\n",
       "      <td>15.070000</td>\n",
       "      <td>15.260000</td>\n",
       "      <td>15.229542</td>\n",
       "      <td>37281400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>2017-12-08</td>\n",
       "      <td>15.510000</td>\n",
       "      <td>15.680000</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>15.319362</td>\n",
       "      <td>39584500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>15.480000</td>\n",
       "      <td>15.570000</td>\n",
       "      <td>15.370000</td>\n",
       "      <td>15.380000</td>\n",
       "      <td>15.349302</td>\n",
       "      <td>21281600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>15.360000</td>\n",
       "      <td>15.490000</td>\n",
       "      <td>15.180000</td>\n",
       "      <td>15.490000</td>\n",
       "      <td>15.459082</td>\n",
       "      <td>36201200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>15.650000</td>\n",
       "      <td>15.680000</td>\n",
       "      <td>15.110000</td>\n",
       "      <td>15.180000</td>\n",
       "      <td>15.149701</td>\n",
       "      <td>46828900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>15.310000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.010000</td>\n",
       "      <td>14.980041</td>\n",
       "      <td>37177300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>15.050000</td>\n",
       "      <td>15.240000</td>\n",
       "      <td>14.950000</td>\n",
       "      <td>14.950000</td>\n",
       "      <td>14.920160</td>\n",
       "      <td>55668300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>15.160000</td>\n",
       "      <td>15.330000</td>\n",
       "      <td>15.130000</td>\n",
       "      <td>15.220000</td>\n",
       "      <td>15.189621</td>\n",
       "      <td>42760400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>15.180000</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>15.060000</td>\n",
       "      <td>15.140000</td>\n",
       "      <td>15.109781</td>\n",
       "      <td>22639700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>15.210000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>15.170000</td>\n",
       "      <td>15.240000</td>\n",
       "      <td>15.209581</td>\n",
       "      <td>20149700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>15.310000</td>\n",
       "      <td>15.870000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>15.860000</td>\n",
       "      <td>15.828343</td>\n",
       "      <td>47219400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.890000</td>\n",
       "      <td>15.690000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.718563</td>\n",
       "      <td>18708500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.718563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.990000</td>\n",
       "      <td>15.690000</td>\n",
       "      <td>15.970000</td>\n",
       "      <td>15.938125</td>\n",
       "      <td>22173100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>15.990000</td>\n",
       "      <td>16.139999</td>\n",
       "      <td>15.980000</td>\n",
       "      <td>16.049999</td>\n",
       "      <td>16.017963</td>\n",
       "      <td>23552200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.129999</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.067865</td>\n",
       "      <td>19011500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.067865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1245 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Open       High        Low      Close  Adj Close  \\\n",
       "0     2013-01-02  19.990000  20.209999  19.690001  19.690001  18.086271   \n",
       "1     2013-01-03  19.809999  20.400000  19.700001  20.400000  18.738441   \n",
       "2     2013-01-04  20.330000  20.620001  20.170000  20.430000  18.766001   \n",
       "3     2013-01-07  20.480000  20.670000  19.950001  20.080000  18.444506   \n",
       "4     2013-01-08  20.110001  20.230000  19.459999  19.500000  17.911745   \n",
       "5     2013-01-09  19.639999  19.870001  19.459999  19.680000  18.077084   \n",
       "6     2013-01-10  19.770000  20.049999  19.540001  19.830000  18.214869   \n",
       "7     2013-01-11  19.850000  20.040001  19.700001  19.879999  18.260794   \n",
       "8     2013-01-14  20.010000  20.240000  19.690001  19.719999  18.113827   \n",
       "9     2013-01-15  20.010000  20.240000  19.690001  19.820000  18.205681   \n",
       "10    2013-01-16  19.889999  19.889999  19.600000  19.840000  18.224054   \n",
       "11    2013-01-17  19.860001  19.930000  19.600000  19.709999  18.104639   \n",
       "12    2013-01-18  19.799999  19.889999  19.540001  19.580000  17.985229   \n",
       "13    2013-01-21  19.570000  19.600000  19.270000  19.389999  17.810705   \n",
       "14    2013-01-22  19.420000  19.610001  19.230000  19.580000  17.985229   \n",
       "15    2013-01-23  19.420000  19.629999  19.230000  19.549999  17.957674   \n",
       "16    2013-01-24  19.370001  19.750000  19.370001  19.610001  18.012787   \n",
       "17    2013-01-28  19.730000  19.809999  19.270000  19.370001  17.792336   \n",
       "18    2013-01-29  19.350000  19.370001  18.840000  19.110001  17.553513   \n",
       "19    2013-01-30  18.990000  18.990000  18.170000  18.200001  16.717628   \n",
       "20    2013-01-31  18.260000  18.330000  17.900000  18.080000  16.607405   \n",
       "21    2013-02-01  18.139999  18.650000  18.120001  18.459999  16.956451   \n",
       "22    2013-02-04  18.160000  18.350000  17.889999  18.000000  16.533920   \n",
       "23    2013-02-05  17.280001  18.290001  17.260000  18.080000  16.607405   \n",
       "24    2013-02-06  17.930000  18.000000  17.530001  17.600000  16.166500   \n",
       "25    2013-02-07  17.750000  17.980000  17.320000  17.500000  16.074644   \n",
       "26    2013-02-08  17.549999  17.780001  17.379999  17.740000  16.295095   \n",
       "27    2013-02-13  17.950001  18.000000  17.730000  17.799999  16.350208   \n",
       "28    2013-02-14  17.790001  17.900000  17.580000  17.670000  16.230797   \n",
       "29    2013-02-15  17.610001  17.790001  17.530001  17.629999  16.194056   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "1215  2017-11-20  16.020000  16.020000  16.020000  16.020000  15.988025   \n",
       "1216  2017-11-21  16.150000  16.309999  15.850000  15.900000  15.868263   \n",
       "1217  2017-11-22  16.090000  16.240000  15.930000  16.110001  16.077845   \n",
       "1218  2017-11-23  15.980000  16.260000  15.940000  16.190001  16.157686   \n",
       "1219  2017-11-24  16.250000  16.370001  16.040001  16.100000  16.067865   \n",
       "1220  2017-11-27  16.010000  16.020000  15.780000  15.870000  15.838324   \n",
       "1221  2017-11-28  15.930000  16.040001  15.810000  15.840000  15.808384   \n",
       "1222  2017-11-29  15.870000  15.920000  15.320000  15.330000  15.299401   \n",
       "1223  2017-11-30  15.300000  15.470000  14.990000  15.380000  15.349302   \n",
       "1224  2017-12-01  15.340000  15.770000  15.260000  15.610000  15.578842   \n",
       "1225  2017-12-04  15.650000  15.800000  15.460000  15.480000  15.449101   \n",
       "1226  2017-12-05  15.500000  15.830000  15.210000  15.310000  15.279442   \n",
       "1227  2017-12-06  15.220000  15.700000  15.140000  15.520000  15.489023   \n",
       "1228  2017-12-07  15.300000  15.490000  15.070000  15.260000  15.229542   \n",
       "1229  2017-12-08  15.510000  15.680000  15.350000  15.350000  15.319362   \n",
       "1230  2017-12-11  15.480000  15.570000  15.370000  15.380000  15.349302   \n",
       "1231  2017-12-12  15.360000  15.490000  15.180000  15.490000  15.459082   \n",
       "1232  2017-12-13  15.650000  15.680000  15.110000  15.180000  15.149701   \n",
       "1233  2017-12-14  15.100000  15.310000  15.000000  15.010000  14.980041   \n",
       "1234  2017-12-15  15.050000  15.240000  14.950000  14.950000  14.920160   \n",
       "1235  2017-12-18  15.160000  15.330000  15.130000  15.220000  15.189621   \n",
       "1236  2017-12-19  15.180000  15.250000  15.060000  15.140000  15.109781   \n",
       "1237  2017-12-20  15.210000  15.300000  15.170000  15.240000  15.209581   \n",
       "1238  2017-12-21  15.310000  15.870000  15.300000  15.860000  15.828343   \n",
       "1239  2017-12-22  15.750000  15.890000  15.690000  15.750000  15.718563   \n",
       "1240  2017-12-25  15.750000  15.750000  15.750000  15.750000  15.718563   \n",
       "1241  2017-12-26  15.750000  15.990000  15.690000  15.970000  15.938125   \n",
       "1242  2017-12-27  15.990000  16.139999  15.980000  16.049999  16.017963   \n",
       "1243  2017-12-28  16.100000  16.129999  16.000000  16.100000  16.067865   \n",
       "1244  2017-12-29  16.100000  16.100000  16.100000  16.100000  16.067865   \n",
       "\n",
       "          Volume  \n",
       "0     30182600.0  \n",
       "1     30552600.0  \n",
       "2     36141000.0  \n",
       "3     28069600.0  \n",
       "4     29091300.0  \n",
       "5     24361100.0  \n",
       "6     17526200.0  \n",
       "7     18223600.0  \n",
       "8     28302400.0  \n",
       "9     29633900.0  \n",
       "10    16787800.0  \n",
       "11    19719600.0  \n",
       "12    18913900.0  \n",
       "13    18086200.0  \n",
       "14    23535100.0  \n",
       "15    17200800.0  \n",
       "16    19612600.0  \n",
       "17    20122600.0  \n",
       "18    27097900.0  \n",
       "19    66985800.0  \n",
       "20    33246400.0  \n",
       "21    28860400.0  \n",
       "22    32294300.0  \n",
       "23    77332900.0  \n",
       "24    30886100.0  \n",
       "25    37066400.0  \n",
       "26    31068100.0  \n",
       "27    22328200.0  \n",
       "28    25902900.0  \n",
       "29    25001600.0  \n",
       "...          ...  \n",
       "1215         0.0  \n",
       "1216  45817800.0  \n",
       "1217  37444900.0  \n",
       "1218  15403600.0  \n",
       "1219  18790700.0  \n",
       "1220  28445800.0  \n",
       "1221  30429600.0  \n",
       "1222  45973000.0  \n",
       "1223  52811400.0  \n",
       "1224  42703800.0  \n",
       "1225  43821500.0  \n",
       "1226  30228000.0  \n",
       "1227  39238500.0  \n",
       "1228  37281400.0  \n",
       "1229  39584500.0  \n",
       "1230  21281600.0  \n",
       "1231  36201200.0  \n",
       "1232  46828900.0  \n",
       "1233  37177300.0  \n",
       "1234  55668300.0  \n",
       "1235  42760400.0  \n",
       "1236  22639700.0  \n",
       "1237  20149700.0  \n",
       "1238  47219400.0  \n",
       "1239  18708500.0  \n",
       "1240         0.0  \n",
       "1241  22173100.0  \n",
       "1242  23552200.0  \n",
       "1243  19011500.0  \n",
       "1244         0.0  \n",
       "\n",
       "[1245 rows x 7 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pré-processamento dos dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em relação ao valores NaN, podemos realizar três ações:\n",
    "\n",
    "* Exclução desses valores\n",
    "* Substituição por 0\n",
    "* Substituir pela média de cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         3\n",
       "High         3\n",
       "Low          3\n",
       "Close        3\n",
       "Adj Close    3\n",
       "Volume       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visto que a quantidade de valores do tipo NaN é relativamente baixa em relação aos 1245 dados do data set, podemos optar por apagar esses registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = dataFrame.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 7)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, podemos verificar se a função dropna(), conseguiu apagar estes valores nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para treinarmos nosso modelo, podemos escolher uma das features temporais, que possa nos auxiliar na nossa target(alvo do modelo):\n",
    "\n",
    "* Nesse contexto, optei por escolher a feature ***Open*** referente à abertura da ação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treinamento = dataFrame.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.99    ]\n",
      " [19.809999]\n",
      " [20.33    ]\n",
      " ...\n",
      " [15.99    ]\n",
      " [16.1     ]\n",
      " [16.1     ]]\n"
     ]
    }
   ],
   "source": [
    "print(base_treinamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso modelo trabalha com valores reais, podemos dizer assim. Dessa forma, podemos encontrar valores muito altos, que podem influenciar no treinamento. Para resolver essa problemática, podemos escolher duas opções:\n",
    "\n",
    "* Normalização dos dados\n",
    "\n",
    "* Padronização dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambas as técnicas trabalham com o um único objetivo: deixar os dados na mesma grandeza. Para isso, veremos como cada uma trabalha, de forma individual:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalização**\n",
    "\n",
    "![Min-Max fórmula](https://miro.medium.com/max/202/1*9N7QdpE_CfvkTyirk7_oWw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padronização**\n",
    "\n",
    "<img src=\"https://d1whtlypfis84e.cloudfront.net/guides/wp-content/uploads/2020/04/04155631/1426878678.png \" alt=\"drawing\" width=\"150\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste modelo, vamos utilizar a técnica de **Normalização**, visto a tratar os outliers nos nossos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para normalizar esse dados, vamos utilizar a função MinMaxScaler(), que irá transformar os dados em uma escala de 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = MinMaxScaler(feature_range = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treinamento_normalizer = normalizador.fit_transform(base_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76501938],\n",
       "       [0.7562984 ],\n",
       "       [0.78149225],\n",
       "       ...,\n",
       "       [0.57122093],\n",
       "       [0.57655039],\n",
       "       [0.57655039]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_treinamento_normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estrutura da base para previsão temporal I**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando trabalha-se com dados temporais é preciso definir um intervalo de tempo entre os dados e o alvo. Neste caso, podemos pegar um registro que tenha registros anteriores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo: \n",
    "\n",
    "| Dia da semana | Dia | Preço |\n",
    "|---------------|-----|-------|\n",
    "| Quinta-feira  | 03  | 19,99 |\n",
    "| Sexta-feira   | 04  | 19,80 |\n",
    "| Segunda-feira | 07  | 20,33 |\n",
    "| Terça-feira   | 08  | 20,48 |\n",
    "| Quarta-feira  | 09  | 20,11 |\n",
    "\n",
    "Para prever o preço da Quarta-feira, dia 09, precisamos pegar os valores das 4 datas anteriores:\n",
    "\n",
    "| **Previsores** |   **Preço real**|\n",
    "|---------------|-----|\n",
    "| 19,99 19,80 20,33 20,48 20,11  | 20,11  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estrutura da base para previsão temporal II**\n",
    "\n",
    "* Prever o preço real através do 90 valores anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = []\n",
    "preco_real = []\n",
    "\n",
    "for i in range(90, 1242):\n",
    "    previsores.append(base_treinamento_normalizer[i-90:i, 0])\n",
    "    preco_real.append(base_treinamento_normalizer[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores, preco_real = np.array(previsores), np.array(preco_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 90)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a utilização da biblioteca Keras, nosso vetor de entradas precisa manter uma dimensão 3D com o formato:\n",
    "\n",
    "                (batch_size, timesteps, input_dim)\n",
    "Sendo:\n",
    "\n",
    "* Batch_size - refere-se ao número de exemplos de treinamento usados em uma intereção\n",
    "\n",
    "* Timesteps - refere-se a descrição da forma dos dados\n",
    "\n",
    "* Input_dim - refere-se ao número de entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = np.reshape(previsores, (previsores.shape[0],previsores.shape[1],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estrutura da Rede Neural Recorrente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (previsores.shape[1],1)))\n",
    "regressor.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dense(units = 1,activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error',\n",
    "                  metrics = ['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0344 - mean_squared_error: 0.0344\n",
      "Epoch 2/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0170 - mean_squared_error: 0.0170\n",
      "Epoch 3/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
      "Epoch 4/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 5/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 6/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 7/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 8/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 9/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 10/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 11/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 12/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 13/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 14/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 15/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 16/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 17/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 18/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 19/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 20/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 21/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 22/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 23/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 24/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 25/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 26/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 27/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 28/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 29/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 30/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 31/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 32/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 33/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 34/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 35/100\n",
      "1152/1152 [==============================] - 7s 7ms/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 36/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 37/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 38/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 39/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 40/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 41/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 42/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 43/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 44/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 45/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 46/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 47/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 48/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 49/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 50/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 51/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 52/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 53/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 54/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 55/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 56/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 57/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 58/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 59/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 60/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 61/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 62/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 63/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 64/100\n",
      "1152/1152 [==============================] - 9s 7ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 65/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 66/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 67/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 68/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 69/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 70/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 71/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 73/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 74/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 75/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 76/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 77/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 78/100\n",
      "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 79/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 80/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 81/100\n",
      "1152/1152 [==============================] - 11s 10ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 82/100\n",
      "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 83/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 84/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 85/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 86/100\n",
      "1152/1152 [==============================] - 6s 6ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 87/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 88/100\n",
      "1152/1152 [==============================] - 6s 6ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 89/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 90/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 91/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 92/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 93/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 94/100\n",
      "1152/1152 [==============================] - 6s 6ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 95/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 96/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 97/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 98/100\n",
      "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 99/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 100/100\n",
      "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fefcedca208>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(previsores, preco_real, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Previsão de preços de açẽs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_teste = pd.read_csv('petr4_teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.516966</td>\n",
       "      <td>33461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>16.490000</td>\n",
       "      <td>16.719999</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.666668</td>\n",
       "      <td>55940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>16.780001</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>16.620001</td>\n",
       "      <td>16.730000</td>\n",
       "      <td>16.696608</td>\n",
       "      <td>37064900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>16.570000</td>\n",
       "      <td>16.830000</td>\n",
       "      <td>16.796408</td>\n",
       "      <td>26958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>16.740000</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.709999</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.996010</td>\n",
       "      <td>28400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>17.160000</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.996010</td>\n",
       "      <td>35070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>16.920000</td>\n",
       "      <td>17.049999</td>\n",
       "      <td>16.770000</td>\n",
       "      <td>16.799999</td>\n",
       "      <td>16.766466</td>\n",
       "      <td>28547700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>16.879999</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>16.840000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>17.215569</td>\n",
       "      <td>37921500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>17.040001</td>\n",
       "      <td>17.410000</td>\n",
       "      <td>17.020000</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>17.265469</td>\n",
       "      <td>45912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>17.320000</td>\n",
       "      <td>17.440001</td>\n",
       "      <td>17.150000</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>17.315371</td>\n",
       "      <td>28945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>17.840000</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>17.650000</td>\n",
       "      <td>17.614771</td>\n",
       "      <td>58618300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>17.920000</td>\n",
       "      <td>18.360001</td>\n",
       "      <td>17.809999</td>\n",
       "      <td>18.360001</td>\n",
       "      <td>18.323355</td>\n",
       "      <td>58488900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>18.530001</td>\n",
       "      <td>17.930000</td>\n",
       "      <td>18.219999</td>\n",
       "      <td>18.183632</td>\n",
       "      <td>48575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>18.309999</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>18.030001</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>18.223553</td>\n",
       "      <td>33470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>18.469999</td>\n",
       "      <td>18.090000</td>\n",
       "      <td>18.469999</td>\n",
       "      <td>18.433134</td>\n",
       "      <td>33920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>18.459999</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.240000</td>\n",
       "      <td>18.203592</td>\n",
       "      <td>35567700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>19.629999</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.301397</td>\n",
       "      <td>89768200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.301397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>19.620001</td>\n",
       "      <td>19.980000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.890221</td>\n",
       "      <td>81989500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>19.670000</td>\n",
       "      <td>20.049999</td>\n",
       "      <td>19.570000</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>19.810381</td>\n",
       "      <td>55726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.360001</td>\n",
       "      <td>19.490000</td>\n",
       "      <td>19.451097</td>\n",
       "      <td>46203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>19.740000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>19.660681</td>\n",
       "      <td>41576600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       Open       High        Low      Close  Adj Close  \\\n",
       "0   2018-01-02  16.190001  16.549999  16.190001  16.549999  16.516966   \n",
       "1   2018-01-03  16.490000  16.719999  16.370001  16.700001  16.666668   \n",
       "2   2018-01-04  16.780001  16.959999  16.620001  16.730000  16.696608   \n",
       "3   2018-01-05  16.700001  16.860001  16.570000  16.830000  16.796408   \n",
       "4   2018-01-08  16.740000  17.030001  16.709999  17.030001  16.996010   \n",
       "5   2018-01-09  17.030001  17.160000  16.959999  17.030001  16.996010   \n",
       "6   2018-01-10  16.920000  17.049999  16.770000  16.799999  16.766466   \n",
       "7   2018-01-11  16.879999  17.299999  16.840000  17.250000  17.215569   \n",
       "8   2018-01-12  17.040001  17.410000  17.020000  17.299999  17.265469   \n",
       "9   2018-01-15  17.320000  17.440001  17.150000  17.350000  17.315371   \n",
       "10  2018-01-16  17.350000  17.840000  17.299999  17.650000  17.614771   \n",
       "11  2018-01-17  17.920000  18.360001  17.809999  18.360001  18.323355   \n",
       "12  2018-01-18  18.350000  18.530001  17.930000  18.219999  18.183632   \n",
       "13  2018-01-19  18.309999  18.420000  18.030001  18.260000  18.223553   \n",
       "14  2018-01-22  18.260000  18.469999  18.090000  18.469999  18.433134   \n",
       "15  2018-01-23  18.400000  18.459999  18.000000  18.240000  18.203592   \n",
       "16  2018-01-24  18.420000  19.629999  18.420000  19.340000  19.301397   \n",
       "17  2018-01-25  19.340000  19.340000  19.340000  19.340000  19.301397   \n",
       "18  2018-01-26  19.620001  19.980000  19.100000  19.930000  19.890221   \n",
       "19  2018-01-29  19.670000  20.049999  19.570000  19.850000  19.810381   \n",
       "20  2018-01-30  19.770000  19.770000  19.360001  19.490000  19.451097   \n",
       "21  2018-01-31  19.740000  19.930000  19.680000  19.700001  19.660681   \n",
       "\n",
       "      Volume  \n",
       "0   33461800  \n",
       "1   55940900  \n",
       "2   37064900  \n",
       "3   26958200  \n",
       "4   28400000  \n",
       "5   35070900  \n",
       "6   28547700  \n",
       "7   37921500  \n",
       "8   45912100  \n",
       "9   28945400  \n",
       "10  58618300  \n",
       "11  58488900  \n",
       "12  48575800  \n",
       "13  33470200  \n",
       "14  33920000  \n",
       "15  35567700  \n",
       "16  89768200  \n",
       "17         0  \n",
       "18  81989500  \n",
       "19  55726200  \n",
       "20  46203000  \n",
       "21  41576600  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos fazendo o uso apenas da feature **Open**, vamos extrai-la:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "preco_real_teste = base_teste.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos trabalhar com tipos de dados iguais, para evitar erros com a nossa Rede Neural Recorrente, para isso vamos concatenar as suas bases(treino e teste), para facilitar igualdade de tipos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_completa = pd.concat((dataFrame['Open'], base_teste['Open']), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = base_completa[len(base_completa) - len(base_teste) - 90:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar a função reshape, para remodelar nosso vetor numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = entradas.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, colocaremos nossos dados na mesma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = normalizador.transform(entradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47141473],\n",
       "       [0.46317829],\n",
       "       [0.46463178],\n",
       "       [0.45203488],\n",
       "       [0.46753876],\n",
       "       [0.47286822],\n",
       "       [0.50242248],\n",
       "       [0.50629845],\n",
       "       [0.52422481],\n",
       "       [0.52810078],\n",
       "       [0.51744186],\n",
       "       [0.52228682],\n",
       "       [0.52034884],\n",
       "       [0.5247093 ],\n",
       "       [0.52664729],\n",
       "       [0.52422481],\n",
       "       [0.52810078],\n",
       "       [0.53536822],\n",
       "       [0.56443798],\n",
       "       [0.55232558],\n",
       "       [0.56153101],\n",
       "       [0.56492248],\n",
       "       [0.55717054],\n",
       "       [0.54118217],\n",
       "       [0.54748062],\n",
       "       [0.53246124],\n",
       "       [0.55232558],\n",
       "       [0.56686047],\n",
       "       [0.56589147],\n",
       "       [0.55523256],\n",
       "       [0.55281008],\n",
       "       [0.57800383],\n",
       "       [0.57994186],\n",
       "       [0.5755814 ],\n",
       "       [0.58284884],\n",
       "       [0.57945736],\n",
       "       [0.57848832],\n",
       "       [0.58236429],\n",
       "       [0.57170543],\n",
       "       [0.5809109 ],\n",
       "       [0.58575586],\n",
       "       [0.58575586],\n",
       "       [0.59738377],\n",
       "       [0.60949617],\n",
       "       [0.60901163],\n",
       "       [0.6187015 ],\n",
       "       [0.61531008],\n",
       "       [0.61967054],\n",
       "       [0.61531008],\n",
       "       [0.61821701],\n",
       "       [0.62257747],\n",
       "       [0.63517437],\n",
       "       [0.60513571],\n",
       "       [0.61482553],\n",
       "       [0.6061046 ],\n",
       "       [0.60513571],\n",
       "       [0.60271313],\n",
       "       [0.54021318],\n",
       "       [0.55329457],\n",
       "       [0.56782946],\n",
       "       [0.57267442],\n",
       "       [0.57897287],\n",
       "       [0.57606589],\n",
       "       [0.57073643],\n",
       "       [0.58381783],\n",
       "       [0.57218992],\n",
       "       [0.56831395],\n",
       "       [0.56540698],\n",
       "       [0.5377907 ],\n",
       "       [0.53972868],\n",
       "       [0.55474806],\n",
       "       [0.54748062],\n",
       "       [0.53391473],\n",
       "       [0.5377907 ],\n",
       "       [0.54796512],\n",
       "       [0.54651163],\n",
       "       [0.54069767],\n",
       "       [0.55474806],\n",
       "       [0.52810078],\n",
       "       [0.52567829],\n",
       "       [0.53100775],\n",
       "       [0.53197674],\n",
       "       [0.53343023],\n",
       "       [0.53827519],\n",
       "       [0.55959302],\n",
       "       [0.55959302],\n",
       "       [0.55959302],\n",
       "       [0.57122093],\n",
       "       [0.57655039],\n",
       "       [0.57655039],\n",
       "       [0.5809109 ],\n",
       "       [0.59544574],\n",
       "       [0.60949617],\n",
       "       [0.6056202 ],\n",
       "       [0.60755814],\n",
       "       [0.62160858],\n",
       "       [0.61627907],\n",
       "       [0.61434104],\n",
       "       [0.62209307],\n",
       "       [0.63565891],\n",
       "       [0.6371124 ],\n",
       "       [0.66472868],\n",
       "       [0.68556202],\n",
       "       [0.68362398],\n",
       "       [0.68120155],\n",
       "       [0.6879845 ],\n",
       "       [0.68895349],\n",
       "       [0.73352713],\n",
       "       [0.74709307],\n",
       "       [0.7495155 ],\n",
       "       [0.75436047],\n",
       "       [0.75290698]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos colocar nossos dados de teste em uma lista. Dessa forma, iremos preencher nosso vetor X_teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste = []\n",
    "for i in range(90,112):\n",
    "    X_teste.append(entradas[i-90:i, 0])\n",
    "\n",
    "X_teste = np.array(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 90)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste = np.reshape(X_teste, (X_teste.shape[0], X_teste.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 90, 1)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, iremos realizar nossas previções:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = regressor.predict(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizarmos as previsoes, iremos fazer um processo inverso à normalização. Dessa forma, iremos visualizar os preços em escalas reais ao início. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = normalizador.inverse_transform(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.060324],\n",
       "       [16.11508 ],\n",
       "       [16.33288 ],\n",
       "       [16.61174 ],\n",
       "       [16.64482 ],\n",
       "       [16.64558 ],\n",
       "       [16.845572],\n",
       "       [16.867891],\n",
       "       [16.815756],\n",
       "       [16.903109],\n",
       "       [17.137545],\n",
       "       [17.237164],\n",
       "       [17.61667 ],\n",
       "       [18.053425],\n",
       "       [18.134068],\n",
       "       [18.079782],\n",
       "       [18.166327],\n",
       "       [18.232475],\n",
       "       [18.873707],\n",
       "       [19.280882],\n",
       "       [19.352222],\n",
       "       [19.414549]], dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.190001],\n",
       "       [16.49    ],\n",
       "       [16.780001],\n",
       "       [16.700001],\n",
       "       [16.74    ],\n",
       "       [17.030001],\n",
       "       [16.92    ],\n",
       "       [16.879999],\n",
       "       [17.040001],\n",
       "       [17.32    ],\n",
       "       [17.35    ],\n",
       "       [17.92    ],\n",
       "       [18.35    ],\n",
       "       [18.309999],\n",
       "       [18.26    ],\n",
       "       [18.4     ],\n",
       "       [18.42    ],\n",
       "       [19.34    ],\n",
       "       [19.620001],\n",
       "       [19.67    ],\n",
       "       [19.77    ],\n",
       "       [19.74    ]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preco_real_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que as previsões não ficaram distantes aos valores reais. Dessa maneira, podemos visualizar a média das previsoes e a média do preço real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.519163"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.87454563636364"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preco_real_teste.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3553825046497714\n"
     ]
    }
   ],
   "source": [
    "diferenca = preco_real_teste.mean() - previsoes.mean()\n",
    "print(diferenca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizarmos o quanto as previsoes puderam se aproximar dos valores reais, podemos fazer um gráfico com ambos os vetores. Para isso, vamos utilizar a biblioteca **matplotlib**, para plotar esses valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(preco_real_teste, color = 'red', label = 'Preço real')\n",
    "plt.plot(previsoes, color = 'blue', label = 'Previsoes do modelo')\n",
    "plt.title('Previsões dos preços das ações')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Valor')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referências**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.udemy.com/course/deep-learning-com-python-az-curso-completo/learn/lecture/10897310#questions\n",
    "\n",
    "https://translate.googleusercontent.com/translate_c?depth=1&hl=pt-BR&prev=search&rurl=translate.google.com&sl=en&sp=nmt4&u=https://stackoverflow.com/questions/38714959/understanding-keras-lstms&usg=ALkJrhgwRgxszeum-5XuG2HTiE0KM75Wog\n",
    "\n",
    "https://www.google.com/search?q=LSTM&client=ubuntu&hs=DAN&channel=fs&sxsrf=ALeKk02TzfQeiFwQ3Hw3VX9kUWN9kBiJ6g:1592424774740&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiBip7I1InqAhU0D7kGHfcuDHsQ_AUoAXoECA8QAw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
